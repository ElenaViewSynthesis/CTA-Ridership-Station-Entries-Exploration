{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2 Starter Code\n",
    "\n",
    "You can use this notebook to arrive at the answers for the quiz on Model Evaluation. It also provides you some hints and starter code.\n",
    "\n",
    "For this quiz, we use a dataset derived from a variety of sources, including the Chicago Open Data portal and the Census. For details, see the quiz.\n",
    "\n",
    "First, we'll load the data for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crime_acs = pd.read_csv(\"../data/crime_acs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your target variable will be Arrest. Your classifier should consider the following features:\n",
    "\n",
    "- `Primary Type`\n",
    "- `Ward`\n",
    "- `FBI Code`\n",
    "- `Percent White`\n",
    "- `Percent Black`\n",
    "- `Median Income`\n",
    "\n",
    "## Part 1: Data Preparation\n",
    "\n",
    "\n",
    "### Question 1\n",
    "First, create the training and testing sets. Use a split of .2, and a `random_state` of 0\n",
    "As a quick sanity check, how many rows are in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into training and testing sets using random_state=0. Then, find the number of rows in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Next, convert the label \"Arrest\" into a numerical (rather than boolean) feature in both your training and testing data (i.e., a 1 for an arrest, and a 0 for no arrest).\n",
    "\n",
    "In the training data, what percentage of recorded crimes resulted in an arrest? (express as a decimal between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Arrest column, convert True to 1 and False to 0\n",
    "# Do this for both the train and test sets\n",
    "\n",
    "# Now, in the training data, find the fraction of crimes that resulted in arrest\n",
    "# Your answer may look like train_df['Arrest'].value_counts() / train_df.shape[0]\n",
    "# Hint: your answer should be a number between .2 and .3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Next, we will want to pre-process the continuous numeric features (Percent White, Percent Black, Median Income). This will mean normalizing each feature, and imputing missing values.\n",
    "\n",
    "First, note that administrative data often uses encodings to indicate missing data.\n",
    "\n",
    "So we should make sure to perform sanity checks (e.g. ensure that your percentages fall between 0 and 1, that income follows a reasonable distribution, etc.) \n",
    "\n",
    "The `Median Income` uses such an administrative code for some missing values--what is that code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a  look at the Median Income column--some values may be NaN, but some will be an administrative code\n",
    "# Figure out what that number is. Hint: The code is a number less than zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Replace the administrative code in question 3 with NaN for the training and testing sets. Then, normalize `Percent White`, `Percent Black`, and `Median Income` in the way that we have learned:\n",
    "1. find the mean and standard deviation in the training set.\n",
    "\n",
    "2. Subtract the training mean from each value, then divide by the training standard deviation.\n",
    "\n",
    "Finally, replace the missing values with the mean in its column.\n",
    "\n",
    "After going through these steps--normalizing and imputing missing values--what is the mean value in the test set for \"Median Income\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First, replace the administrative code you found previously with NaN for the test and train sets.\n",
    "# If \"admin_code\" is your answer to the previous question your code might look like:\n",
    "train_df['Median Income'].replace({admin_code: np.NaN}, inplace=True)\n",
    "\n",
    "# 2. Now, normalize. You can do this a few different ways, but you might consider writing a for loop.\n",
    "# If you go that path the code below gets you started:\n",
    "cols = [\"Percent White\", \"Percent Black\", \"Median Income\"]\n",
    "for col in cols:\n",
    "    mean = train_df[col].mean()\n",
    "    std = train_df[col].std()\n",
    "    (train[col] - mean)/std\n",
    "    # Now, do the same for the test set, using the mean and standard deviation from the training set\n",
    "\n",
    "    # Finally, replace the missing values in the column with the training mean, e.g., by using fillna(mean)\n",
    "\n",
    "# Now, the sanity check: after this process, get the test mean for Median Income\n",
    "# Hint: It should be between 2000 and 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  5\n",
    "\n",
    "There is just one more data preparation step, encoding features from the categorical variables (\"Primary Type\", \"Ward\", and \"FBI Code\"). The standard way to encode categorical features in machine learning is through one-hot encoding. The function \"pd.get_dummies\" will be useful. \n",
    "\n",
    "An inherent issue arises with this approach when a value appears in either your training or testing data, but not in both. If a value appears in your training set but not your testing set, create a column with all 0's in your testing set. If a value appears in your testing set but not your training set, drop it from your testing data. \n",
    "So:\n",
    "1.  Use get_dummies to one-hot encode \"Primary Type\", \"Ward\", and \"FBI Code\"\n",
    "2. For features that appear in the training data but not testing data, create them and populate them with 0's\n",
    "3. Drop features that appear in the testing data but not training data\n",
    "4. Finally, make sure that the columns that we aren't going to use for classification are dropped. These are: [`Date`, `Description`, `Location Description`,`Domestic`, `Beat`, `District`, `Block`, `Community Area`]\n",
    "\n",
    "How many columns are now in your training and testing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. One-hot encode these columns using get_dummies()\n",
    "encode_cols = ['Primary Type', 'Ward', 'FBI Code']\n",
    "#Your code to on-hot encode here\n",
    "\n",
    "# Now, here is some code to get the columns as lists:\n",
    "train_cols = set(train_df.columns.to_list())\n",
    "test_cols = set(train_df.columns.to_list())\n",
    "\n",
    "# 2. For features in the training data but not testing data, create them and populate with 0\n",
    "# Your code to find the columns in training but not testing\n",
    "# Sample code to set them to zero:\n",
    "for missing_col in_training_not_testing:\n",
    "    test_df[missing_col] = 0\n",
    "    \n",
    "# 3. For features in testing but not training, drop them\n",
    "# Your code to find features in testing but not training\n",
    "# Sample code to drop them:\n",
    "for missing_col in testing_not_training:\n",
    "    test_df.drop(columns=in_test_not_train, inplace=True)\n",
    "\n",
    "# Finally, drop the columns that will not be used for your model from both--these are given above\n",
    "# How many are you left with?\n",
    "# Hint: It should be between 100 and 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below performs a sanity check by verifying that your training set and your testing set wound up with the same features, and that you have successfully imputed all missing values.\n",
    "\n",
    "You can run it before moving on to modeling as a simple check to make sure you're in a good place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(train_df, test_df): \n",
    "    \n",
    "    # Sort features alphabetically\n",
    "    train_df = train_df.reindex(sorted(train_df.columns), axis=1)\n",
    "    test_df = test_df.reindex(sorted(test_df.columns), axis=1)\n",
    "\n",
    "    # Check that they have the same features\n",
    "    if (train_df.columns == test_df.columns).all():\n",
    "        print(\"Success: Features match\")\n",
    "\n",
    "    # Check that no NAs remain\n",
    "    if  not train_df.isna().sum().astype(bool).any() and \\\n",
    "        not test_df.isna().sum().astype(bool).any():\n",
    "        print(\"Success: No NAs remain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Modeling\n",
    "\n",
    "In this part, you will train and evaluate models using different classification techniques and hyperparameters. You will now need to separate your train and test data into the training and testing features and target variables.\n",
    "\n",
    "### Question 6\n",
    "\n",
    "As mentioned, the target variable will be `Arrest`; train on the other features.\n",
    "\n",
    "First, logistic regression. Use a GridSearch with 2-fold cross validation, and try tuning the penalty and the value for C. \n",
    "For the penalty, try l2 and no penalty.\n",
    "For C, try the values (0.01, 0.1, 1).\n",
    "Evaluate based on accuracy.\n",
    "Which combination of penalty and C gives the best results from the GridSearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need it, you can load train and test data that has been prepared for you, per the steps above\n",
    "#train_df = pd.read_csv(\"../data/quiz2_train.csv\")\n",
    "#test_df = pd.read_csv(\"../data/quiz2_test.csv\")\n",
    "\n",
    "# Try l2 and no penalty\n",
    "# For C, try .01, .1, 1\n",
    "# Use 2-fold cross validation\n",
    "# Use random_state = 0--e.g., LogisticRegression(random_state=0)\n",
    "# What combination gives the best mean accuracy?\n",
    "# Hint: you can access results using grid_model.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Next, try tuning a linear support vector machine classifier. Again, use 2-fold cross-validation, and for C try the values (0.01, 0.1, 1). Once again, score on accuracy. Which value for C produces the best score in the GridSearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but this time with a linear SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "The last model type you want to consider is a Naive Bayes classifier. Likewise, use 2-fold cross-validation, and evaluate on accuracy. What is the mean accuracy score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, naive Bayes. No need to use GridSearch for this one, since you're not tuning any hyperparameters\n",
    "# You can use cross_val_score:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# do 2-fold cross-validation and give the mean accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Finally, we want to determine which features are most important.\n",
    "\n",
    "For these examples, the SVM with the parameters in question 7 will have slightly edged out the others. Train a Linear SVM classifier with that value for C. \n",
    "\n",
    "For the features used to train this model, which has the largest positive contribution towards classification as positive? (i.e., which has the largest positvie coefficient?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your Linear SVM with the best value you found for C\n",
    "# You can access model coefficients using model.coef_ (the array will be in the same order as the features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
